{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install deepface opencv-python pandas matplotlib seaborn tqdm"
      ],
      "metadata": {
        "id": "GB7fARxAEbLK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from deepface import DeepFace\n",
        "from tqdm import tqdm"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MAG5_ZG3EkFf",
        "outputId": "e5b87cc5-ab19-4e61-be5f-aa8705915538"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-02-13 20:49:01 - Directory /root/.deepface has been created\n",
            "25-02-13 20:49:01 - Directory /root/.deepface/weights has been created\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XuLZ0rEdDfmI",
        "outputId": "a9c6bcb4-4127-475e-9e7f-919392a18bd0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\r  0%|          | 0/1045 [00:00<?, ?it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25-02-13 21:07:09 - facial_expression_model_weights.h5 will be downloaded...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading...\n",
            "From: https://github.com/serengil/deepface_models/releases/download/v1.0/facial_expression_model_weights.h5\n",
            "To: /root/.deepface/weights/facial_expression_model_weights.h5\n",
            "\n",
            "100%|██████████| 5.98M/5.98M [00:00<00:00, 61.2MB/s]\n",
            "100%|█████████▉| 1044/1045 [03:58<00:00,  4.37it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing complete. Heatmap saved as emotion_heatmap.png\n"
          ]
        }
      ],
      "source": [
        "def process_video_emotions(video_path, output_plot=\"heatmap.png\", frame_interval=1):\n",
        "\n",
        "    # Initialize video capture\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    if not cap.isOpened():\n",
        "        raise ValueError(\"Could not open video file\")\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    emotion_data = []\n",
        "    frame_count = 0\n",
        "\n",
        "    with tqdm(total=total_frames) as pbar:\n",
        "        while cap.isOpened():\n",
        "            ret, frame = cap.read()\n",
        "            if not ret:\n",
        "                break\n",
        "\n",
        "            if frame_count % frame_interval == 0:\n",
        "                # Convert frame to RGB\n",
        "                rgb_frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                try:\n",
        "                    # Analyze face and emotions\n",
        "                    analysis = DeepFace.analyze(rgb_frame, actions=['emotion'], enforce_detection=True, silent=True)\n",
        "                    if analysis:\n",
        "                        emotions = analysis[0]['emotion']\n",
        "                        emotions['frame'] = frame_count\n",
        "                        emotions['time'] = frame_count / fps\n",
        "                        emotion_data.append(emotions)\n",
        "                except:\n",
        "                    pass\n",
        "\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # Create DataFrame\n",
        "    df = pd.DataFrame(emotion_data)\n",
        "    if df.empty:\n",
        "        raise ValueError(\"No faces detected in the video\")\n",
        "\n",
        "    # Normalize time for display\n",
        "    df['time'] = df['time'].round(1)\n",
        "\n",
        "    # Create heatmap\n",
        "    plt.figure(figsize=(15, 8))\n",
        "    heatmap_data = df.drop(['frame', 'time'], axis=1, errors='ignore')\n",
        "    sns.heatmap(\n",
        "        heatmap_data.T,\n",
        "        xticklabels=df['time'],\n",
        "        cmap='viridis',\n",
        "        cbar_kws={'label': 'Emotion Intensity'}\n",
        "    )\n",
        "\n",
        "    plt.title(\"Emotion Heatmap Over Time\")\n",
        "    plt.xlabel(\"Time (seconds)\")\n",
        "    plt.ylabel(\"Emotions\")\n",
        "    plt.yticks(rotation=0)\n",
        "    plt.savefig(output_plot, bbox_inches='tight', dpi=300)\n",
        "    plt.close()\n",
        "\n",
        "    return df\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    df = process_video_emotions(\n",
        "        video_path=\"/content/input.mp4\",\n",
        "        output_plot=\"/content/emotion_heatmap.png\",\n",
        "        frame_interval=5  # Process every 5th frame for faster results\n",
        "    )\n",
        "    print(\"Processing complete. Heatmap saved as emotion_heatmap.png\")"
      ]
    }
  ]
}